# üöÄ Case T√©cnico Dadosfera: Modern Data Platform & AI

![Status](https://img.shields.io/badge/Status-Em_Desenvolvimento-yellow)
![Python](https://img.shields.io/badge/Stack-Python_%7C_SQL-blue)
![Cloud](https://img.shields.io/badge/Cloud-GCP_%7C_Neon_%7C_Dadosfera-orange)

> **Autor:** Jo√£o Pedro Santos
> **Processo:** Engenharia de Dados - Dadosfera
> **Per√≠odo:** Dezembro/2025

---

## Objetivo do Projeto
Implementa√ß√£o ponta a ponta de uma Plataforma de Dados Moderna (Modern Data Stack) seguindo a arquitetura **Lakehouse**. O projeto simula um cen√°rio real de engenharia de dados, cobrindo desde a ingest√£o de m√∫ltiplas fontes at√© a aplica√ß√£o de Governan√ßa e Intelig√™ncia Artificial.

---
## Item 0 - Planejamento e Ingest√£o

**Gest√£o √Ågil:** O acompanhamento das tarefas segue a metodologia Kanban.
üìä [**Acesse o Quadro do Projeto (Trello)**](https://trello.com/b/7aWCHtbz/dadosfera)

![Quadro Trello](/docs/images/trello_board.png)

### Estimativa de Esfor√ßo e Custos (Story Points)

Para cumprir o requisito de **Estimativa de Custos e Aloca√ß√£o de Recursos** (Item 0 - Avan√ßado), este projeto adota o sistema de pontua√ß√£o baseado na sequ√™ncia de Fibonacci adaptada.

---

## Item 1 - Sele√ß√£o e Arquitetura de Dados

### O Pivot: De E-commerce para PropTech
Originalmente planejado para Varejo (Olist), o projeto realizou um **Pivot Estrat√©gico** para o setor de Turismo/Imobili√°rio.

* **Dataset:** [Inside Airbnb (Rio de Janeiro)](http://insideairbnb.com/get-the-data/)
* **Estrat√©gia de Volumetria:**
    * O dataset original de *Reviews* possui escala de Big Data (milh√µes de registros).
    * **Decis√£o de Arquitetura:** Para este case, foi aplicada uma filtragem estrat√©gica reduzindo a carga para **~300k linhas**.
    * **Objetivo:** Otimizar o tempo de processamento/custo da pipeline durante a fase de desenvolvimento, mantendo-se ainda **3x acima do requisito m√≠nimo** do case (>100k registros).

* **Justificativa T√©cnica:** A base oferece maior complexidade para engenharia de dados por incluir nativamente:
    1.  **Dados Geoespaciais (GIS):** Pol√≠gonos de bairros (GeoJSON).
    2.  **Dados Desestruturados:** Reviews de usu√°rios para an√°lise de NLP.
    3.  **Dados Relacionais:** Tabelas de propriedades e calend√°rio.

### Arquitetura "Hybrid-Cloud"
A solu√ß√£o integra servi√ßos best-of-breed para compor o Data Lake:
* **Landing Zone:** Google Storage & AWS S3 (Armazenamento de arquivos brutos).
* **Transactional Layer:** Neon PostgreSQL (Simula√ß√£o de banco de produ√ß√£o).
* **Platform Core:** Dadosfera (Ingest√£o, Cat√°logo e Processamento).

---
## Pipelines de Ingest√£o (Item 2.1)
Implementa√ß√£o de pipelines segregadas por dom√≠nio de dados (**Data Mesh**), garantindo que cada tipo de arquivo tenha seu fluxo de tratamento espec√≠fico.

| Pipeline ID | Origem | Destino (Tabela) | Status | Descri√ß√£o | Pipeline | Catalogo
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **PL_INGEST_S3_AIRBNB_LISTINGS** | AWS S3 | [`PUBLIC.LISTINGS`] | ‚úÖ | Dados cadastrais e financeiros (Core). | [Pipeline](https://app.dadosfera.ai/pt-BR/collect/pipelines/6caaa815-5faf-4888-9dd7-3da6451bd67f) | [Cat√°logo](https://app.dadosfera.ai/pt-BR/catalog/data-assets/f1028bb5-30fc-41af-b8dd-11171e50b3f1)
| **PL_INGEST_S3_AIRBNB_REVIEWS** | AWS S3 | `PUBLIC.REVIEWS` | ‚úÖ | Logs de avalia√ß√µes (Alto Volume/Texto). | [Pipeline](https://app.dadosfera.ai/pt-BR/collect/pipelines/ebdcae36-cb08-4670-ba26-98f8757d98aa) | [Cat√°logo](https://app.dadosfera.ai/pt-BR/catalog/data-assets/07faa045-ac65-4442-91f8-8069c853f744)
| **PL_INGEST_S3_AIRBNB_GIS_ZONES** | AWS S3 | `PUBLIC.GIS_ZONES` | ‚úÖ | Dados vetoriais de mapas (GeoJSON). | [Pipeline](https://app.dadosfera.ai/pt-BR/collect/pipelines/bd5f8d0b-acab-4a59-8c8f-9e5a4a3f144b) | [Cat√°logo](https://app.dadosfera.ai/pt-BR/catalog/data-assets/d7c050a6-7668-4546-b16c-ab86b2d70edd)
| **PL_INGEST_NEON_REFERENCE_DATA**| Neon DB | `PUBLIC.NEIGHBOURHOODS` | ‚úÖ | Replica√ß√£o de dados mestres do Postgres. | [Pipeline](https://app.dadosfera.ai/pt-BR/collect/pipelines/6f4c5c79-1784-45a4-be64-34f91e29200b) | [Cat√°logo](https://app.dadosfera.ai/pt-BR/catalog/data-assets/f001ec60-15b0-4248-b381-eccd3ff72f67)
 
---

## Item 3 - Explora√ß√£o e Governan√ßa (Data Lake)

Nesta etapa, focou-se na organiza√ß√£o da **Landing Zone (Camada Bronze)** e na documenta√ß√£o dos ativos para garantir a democratiza√ß√£o do acesso.

### 1. Estrat√©gia de Cataloga√ß√£o
Os ativos foram classificados utilizando **Tags** na plataforma para identificar visualmente a camada e a fun√ß√£o de cada tabela:

* **`Bronze`**: Aplicada a todas as tabelas de ingest√£o (`listings`, `reviews`, `gis_zones`), indicando que cont√™m dados brutos (Raw) e imut√°veis da Landing Zone.
* **`Dimens√£o`**: Aplicada especificamente √† tabela `NEIGHBOURHOODS` (origem Neon), identificando-a antecipadamente como uma tabela de refer√™ncia (Master Data) para o modelo dimensional.

### 2. Dicion√°rio de Dados
A documenta√ß√£o detalhada de cada coluna, tipagem e regras de neg√≥cio foi externalizada para manter este README limpo.

üëâ **[Acesse o Dicion√°rio de Dados Completo (Docs)](docs/data_dictionary.md)**


---

## Arquitetura de Processamento e Intelig√™ncia (Items 4, 5 & 6)

Para a execu√ß√£o das etapas de Qualidade de Dados, Enriquecimento com IA e Modelagem Dimensional, foi adotada uma arquitetura de **Computa√ß√£o Desacoplada (Decoupled Compute)**.

Esta decis√£o estrat√©gica visa garantir a reprodutibilidade do ambiente cient√≠fico e a agilidade no desenvolvimento, mantendo a compatibilidade total com a plataforma de destino (Dadosfera).

#### 1. Estrat√©gia de Processamento (Hybrid ELT)
Devido a restri√ß√µes de acesso ao m√≥dulo de computa√ß√£o nativo da plataforma durante a fase de avalia√ß√£o, implementou-se o padr√£o **"Bring Your Own Compute" (BYOC)**:

1.  **Extract (Cloud):** Os dados brutos residem na Landing Zone (GCP/Dadosfera).
2.  **Transform & Quality (Local/Container):** O processamento pesado (Valida√ß√£o GX, NLP com GPT-4, Modelagem Star Schema) √© executado em containers locais, simulando um *Worker Node* externo.
3.  **Load (Cloud):** Os resultados processados (Camada Gold) s√£o re-ingestados no Data Lake da Dadosfera para consumo via Dashboard.

#### 2. Abstra√ß√£o de I/O (Data Mocking)
Para otimizar custos e lat√™ncia durante o ciclo de desenvolvimento, foi criada uma camada de abstra√ß√£o de leitura para os arquivos locais (`./data/raw/*.csv`) replicando a estrutura do GCP & AWS S3.

## Item 4 - Data Quality & Saneamento (Great Expectations)

Para garantir a confiabilidade dos modelos de IA, implementou-se uma estrat√©gia rigorosa de **Quality Gates** utilizando a biblioteca **Great Expectations (GX)**. O processo foi dividido em duas etapas: Diagn√≥stico (Raw) e Valida√ß√£o Final (Silver).

### Fase 1: Diagn√≥stico da Camada Bronze (Raw)
A primeira execu√ß√£o do GX sobre os dados brutos revelou problemas cr√≠ticos que inviabilizariam o uso direto em Machine Learning:

* **Duplicidade:** 437 IDs de im√≥veis duplicados.
* **Integridade Num√©rica:** 3.789 registros com IDs "sujos" (erros de parser/cabe√ßalhos repetidos) nas tabelas de Reviews.
* **Regras de Neg√≥cio:** 4.398 im√≥veis com `price` nulo ou formatado incorretamente, o que quebraria c√°lculos financeiros.

> **Status Inicial:** ‚ùå FALHA (Expected)

---

## Item 4.1 (B√¥nus) - Transforma√ß√£o Silver & CDM

Para resolver os problemas detectados, foi desenvolvido uma pipeline de transforma√ß√£o [`2_transform_silver.ipynb`](/nootbooks\02-transform_silver.ipynb). Al√©m da limpeza, foi implementado um **Common Data Model (CDM)**, padronizando a nomenclatura das colunas para um padr√£o corporativo leg√≠vel (Enterprise Naming Convention).

### 1. A√ß√µes de Saneamento
* **Cleaning:** Convers√£o for√ßada de tipagem (String -> Float/Int).
* **Filtering:** Remo√ß√£o autom√°tica de linhas onde `ID` ou `Price` eram nulos/inv√°lidos ("Garbage Collection").
* **Deduplication:** Aplica√ß√£o de `drop_duplicates` baseada na Chave Prim√°ria.

### 2. Common Data Model (Schema Padr√£o)
Ado√ß√£o de prefixos sem√¢nticos para facilitar o Self-Service BI:

| Prefixo | Significado | Exemplo Original | Exemplo CDM (Novo) |
| :--- | :--- | :--- | :--- |
| **SK_** | Surrogate/Source Key | `id` | `SK_LISTING` |
| **NM_** | Nome/Texto Curto | `neighbourhood` | `NM_BAIRRO` |
| **VLR_** | Valor Monet√°rio | `price` | `VLR_DIARIA_BRL` |
| **NR_** | N√∫mero/Coordenada | `latitude` | `NR_LATITUDE` |
| **QTD_** | Quantidade/M√©trica | `minimum_nights` | `QTD_MIN_NOITES` |

---

### Fase 3: Valida√ß√£o Final (Quality Gate)

Ap√≥s a transforma√ß√£o, o Great Expectations foi re-executado sobre os dados. O resultado comprova a efic√°cia da pipeline:

**Relat√≥rio de Execu√ß√£o (Silver Layer):**
```text
üìä RELAT√ìRIO: Listings (Silver)
Status Global: ‚úÖ APROVADO
----------------------------------------
‚úÖ [SK_LISTING] Unicidade Garantida
‚úÖ [SK_LISTING] N√£o Nulo
‚úÖ [VLR_DIARIA_BRL] Formato Num√©rico Validado
‚úÖ [QTD_DIAS_DISPONIVEIS] Range L√≥gico (0-365) Validado

üìä RELAT√ìRIO: Reviews (Silver)
Status Global: ‚úÖ APROVADO
----------------------------------------
‚úÖ [SK_REVIEW] Formato Num√©rico Validado
‚úÖ [SK_LISTING] Integridade Referencial (FK)
‚úÖ [NM_REVIEWER] Preenchimento Obrigat√≥rio
```

## Item 5 - Enriquecimento com GenAI & LLMs (Feature Engineering)

Para extrair valor dos dados desestruturados (textos livres em Reviews e T√≠tulos de An√∫ncios), foi implementado um pipeline de **Processamento de Linguagem Natural (NLP)** utilizando a API da OpenAI.

O objetivo n√£o foi apenas "usar IA", mas sim transformar texto em colunas estruturadas para o Dashboard (Itens 7 e 9), permitindo responder perguntas como: *"Qual o sentimento m√©dio dos h√≥spedes?"* ou *"Im√≥veis com vista para o mar s√£o mais caros?"*.

### Estrat√©gia e FinOps (Amostragem Inteligente)
Devido ao volume de dados (300k+ registros), processar a base inteira seria ineficiente e custoso para uma Prova de Conceito (PoC). Adotou-se uma estrat√©gia de **Smart Sampling** com foco em representatividade e economia:

1.  **Amostragem de Reviews (1.000 registros):**
    * **Top 500:** Reviews mais recentes/relevantes (Head).
    * **Random 500:** Sele√ß√£o aleat√≥ria do restante da cauda (Tail) para evitar vi√©s temporal.
2.  **Integridade Referencial de Listings:**
    * Sele√ß√£o autom√°tica dos im√≥veis (`SK_LISTING`) citados nos reviews acima.
    * *Backfill* aleat√≥rio at√© completar 1.000 im√≥veis, garantindo massa de dados para an√°lise cruzada.
3.  **Escolha do Modelo:**
    * **Modelo:** `gpt-4o-mini`.
    * **Custo Estimado da Opera√ß√£o:** < $0.10 USD (para processar os 2.000 registros).

### Engenharia de Prompt (As Miss√µes da IA)

O pipeline executa duas "miss√µes" distintas de classifica√ß√£o, for√ßando a sa√≠da em formato JSON (`response_format={"type": "json_object"}`) para garantir a integra√ß√£o direta com o Pandas.

#### Miss√£o A: An√°lise de Sentimento (Tabela `fact_reviews`)
Transforma coment√°rios subjetivos em m√©tricas quantitativas.
* **Prompt:** *"Atue como um especialista em Customer Experience. Analise o review e retorne um JSON."*
* **Features Geradas:**
    * `SENTIMENTO`: Positivo, Neutro, Negativo.
    * `TOPICO_PRINCIPAL`: Limpeza, Localiza√ß√£o, Ru√≠do, Atendimento, etc.
    * `SUB_TOPICO`: Conforto, Comunica√ß√£o, Valor, Comodidades, Outro.
    * `TOM_DE_URGENCIA`: Avalia√ß√£o precisa de uma a√ß√£o urgente.

#### Miss√£o B: Categoriza√ß√£o de Im√≥veis (Tabela `dim_listings`)
Extrai atributos de neg√≥cio a partir do t√≠tulo criativo do an√∫ncio.
* **Prompt:** *"Atue como um Corretor de Im√≥veis S√™nior. Analise o t√≠tulo do an√∫ncio e classifique."*
* **Features Geradas:**
    * `CATEGORIA_VIBE`: Luxo, Econ√¥mico, Rom√¢ntico, Familiar, Moderno.
    * `TIPO_VISTA`: Vista Mar, Urbana, Natureza, Sem Vista.
    * `PRINCIPAL_CARACTERISTICA`: Palavra √∫nica palavra que destaca o im√≥vel.
    * `PONTO_FORTE`: Resumo de 3 palavras (ex: "Perto do Metr√¥").

### Exemplo de Resultados (De/Para)

| Input (Texto Original) | Output (Enriquecido via LLM) |
| :--- | :--- |
| **Review:** *"O apartamento √© lindo, mas o barulho da rua n√£o deixou a gente dormir. A limpeza estava ok."* | `{ "sentimento": "Negativo", "topico": "Ru√≠do", "sub_topico":Conforto, "tom_de_urgencia": false }` |
| **Listing:** *"COBERTURA DUPLEX VISTA MAR - COPACABANA POSTO 6"* | `{ "vibe": "Luxo", "vista": "Mar", "principal_caracteristica": "Localidade", "destaque": "Cobertura Duplex" }` |

### Persist√™ncia
Os dados enriquecidos foram salvos separadamente na camada Gold para consumo do Data App:
* `data/gold/FACT_REVIEWS.csv`
* `data/gold/DIM_LISTINGS.csv`

## Item 6 - Modelagem de Dados (Data Warehouse)

Para a constru√ß√£o da camada **Gold**, adotou-se a metodologia **Dimensional (Kimball)**, criando um modelo **Star Schema** (Esquema Estrela).

Essa modelagem foi escolhida por ser otimizada para leitura em ferramentas de BI (Power BI/Streamlit) e facilitar consultas anal√≠ticas (OLAP), ao contr√°rio do modelo normalizado (3NF) que prioriza a escrita (OLTP).

### Estrutura do Schema

O modelo √© centrado no evento de avalia√ß√£o ("Review"), cercado pelas dimens√µes de contexto:

#### 1. Fato: `FACT_REVIEWS`
Tabela transacional contendo m√©tricas e chaves estrangeiras.
* **Granularidade:** 1 linha por avalia√ß√£o √∫nica.
* **M√©tricas:** `TOM_DE_URGENCIA` (Boolean/Flag indicando cr√≠ticas severas que exigem a√ß√£o imediata).
* **Dimens√£o Degenerada:** `SENTIMENTO` (Positivo/Neutro/Negativo).

#### 2. Dimens√£o: `DIM_LISTINGS`
Cont√©m os atributos descritivos do im√≥vel, enriquecidos com Features de IA.
* **Atributos:** `NM_ANUNCIO`, `VLR_DIARIA`, `CAT_VIBE_IA` (Luxo/Econ√¥mico...), `CAT_VISTA_IA` (Mar/Urbana...).
* **Slowly Changing Dimension (SCD):** Tratada como Tipo 1 (Sobrescreve valor atual) para simplifica√ß√£o do case.

#### 3. Dimens√£o: `DIM_NEIGHBOURHOODS` (GeoSpatial)
Tabela espacial oriunda do processamento do arquivo `neighbourhoods.geojson`.
* **Feature Especial:** Coluna do tipo `GEOGRAPHY` (Pol√≠gono) no BigQuery, permitindo queries espaciais (ex: `ST_CONTAINS`) para filtrar reviews dentro de zonas geogr√°ficas espec√≠ficas no mapa.

#### 4. Dimens√£o: `DIM_TEMPO`
Calend√°rio fiscal/civil para an√°lises de sazonalidade.
* **Atributos:** Ano, M√™s, Dia da Semana, Flag de Feriado, Flag de Alta Temporada.

---

### Diagrama de Entidade-Relacionamento (DER)

A figura abaixo representa a arquitetura f√≠sica implementada:

![Diagrama de Mermaid](/docs/images/mermaid_diagram.png)

---

## Item 7 - An√°lise de Dados e Insights de Neg√≥cio

Ap√≥s a modelagem da camada Gold, foi realizada a etapa de **An√°lise de Dados**. O objetivo foi executar as consultas SQL desenvolvidas para responder √†s perguntas estrat√©gicas do projeto e validar as hip√≥teses de neg√≥cio.

Utilizando a plataforma Dadosfera para visualiza√ß√£o, consolidamos os dados de *Listings* (Im√≥veis) e *Reviews* (Avalia√ß√µes Enriquecidas com IA) para gerar os seguintes insights:

### Vis√£o Geral da An√°lise

![Overview da An√°lise Airbnb](/docs/images/dashboard_overview.jpg)
*(Figura: Painel consolidado com as respostas para as 5 perguntas de neg√≥cio)*

---

### Principais Descobertas (Data Storytelling)

Com base nas queries executadas na camada Gold, chegamos √†s seguintes conclus√µes:

#### 1. Precifica√ß√£o de Mercado (Baseline)
* **Pergunta:** Qual √© o ticket m√©dio das di√°rias no Rio de Janeiro?
* **Resultado:** **R$ 615,90**.
* **An√°lise:** Este valor serve como √¢ncora para precifica√ß√£o. Im√≥veis muito abaixo disso podem indicar baixa qualidade ou oportunidade (dumping), enquanto valores muito acima precisam justificar o pre√ßo com atributos exclusivos (Vista Mar, Luxo).

#### 2. Perfil da Oferta (Hegemonia de Privacidade)
* **Pergunta:** Qual o tipo de acomoda√ß√£o predominante?
* **Resultado:** **83.2% s√£o Casas/Apartamentos Inteiros**.
* **An√°lise:** O mercado do Rio √© dominado por alugu√©is de temporada completos. A oferta de "Quartos Privativos" (15.8%) e "Compartilhados" (1.0%) √© minorit√°ria, indicando que o p√∫blico alvo busca privacidade total, competindo diretamente com a rede hoteleira.

#### 3. Reputa√ß√£o e Experi√™ncia (Via GenAI)
* **Pergunta:** Quais t√≥picos geram mais elogios ou cr√≠ticas?
* **Resultado:** O t√≥pico **"Localiza√ß√£o"** √© o maior ofensor positivo (barra verde predominante).
* **An√°lise:** A localiza√ß√£o √© o fator decisivo para a satisfa√ß√£o no Rio de Janeiro. Entretanto, pontos operacionais como **"Limpeza"** e **"Check-in"** aparecem com margem para melhoria, sendo onde os anfitri√µes perdem mais pontos.

#### 4. Comportamento de Reserva (Vibe vs. Estadia)
* **Pergunta:** Como o estilo do im√≥vel influencia a exig√™ncia de estadia m√≠nima?
* **Resultado:** Im√≥veis classificados pela IA como **"Luxo"** ou **"Econ√¥mico"** exigem mais noites (m√©dia > 4).
* **An√°lise:**
    * *Luxo:* Foca em estadias longas para diluir custos operacionais altos.
    * *Relaxante/Rom√¢ntico:* Aceitam estadias curtas (finais de semana), facilitando a convers√£o r√°pida.

#### 5. Distribui√ß√£o Geogr√°fica (Mancha de Calor)
* **Pergunta:** Onde se concentram os im√≥veis?
* **Resultado:** Alta densidade na Zona Sul (Orla) e Centro.
* **An√°lise:** O mapa de pontos confirma a satura√ß√£o nos bairros tur√≠sticos cl√°ssicos (Copacabana, Ipanema). Existem vazios urbanos na Zona Norte que representam mercados inexplorados, por√©m com menor demanda tur√≠stica natural.

### Queries SQL:

``` SQL
-- QUEST√ÉO 1: Qual √© o valor m√©dio da di√°ria (Ticket M√©dio) de todos os im√≥veis cadastrados?
SELECT 
	AVG(VLR_DIARIA_BRL) 
FROM TB__OQ3K4Q__GOLD_LISTINGS_PL_INGEST_S3_AIRBNB

-- QUEST√ÉO 2: Qual a distribui√ß√£o de im√≥veis por tipo de acomoda√ß√£o?
SELECT
    DS_TIPO_QUARTO AS TIPO_DE_QUARTO,
    COUNT(SK_LISTING) AS QTD_DE_IMOVEIS
FROM TB__OK6YZB__GOLD_LISTINGS_PL_INGEST_S3_AIRBNB_V2
GROUP BY 1
ORDER BY QTD_DE_IMOVEIS DESC;

-- QUEST√ÉO 3: Como os h√≥spedes est√£o avaliando cada aspecto (t√≥pico) da experi√™ncia?
SELECT 
    CAT_TOPICO,
    CAT_SENTIMENTO,
    COUNT(SK_LISTING) AS QTD_REVIEWS
FROM TB__U5H8NM__GOLD_REVIEWS_PL_INGEST_S3_AIRBNB
GROUP BY CAT_TOPICO, CAT_SENTIMENTO
ORDER BY CAT_TOPICO, QTD_REVIEWS DESC;

-- QUEST√ÉO 4: Qual √© a pol√≠tica de estadia m√≠nima exigida para cada perfil de im√≥vel?
SELECT 
 CAT_VIBE_IA AS CATEGORIA,
 COUNT(SK_LISTING) AS QUANTIDADE_IMOVEIS,
 ROUND(AVG(QTD_MIN_NOITES),0) AS MEDIA_MIN_NOITES
FROM TB__OK6YZB__GOLD_LISTINGS_PL_INGEST_S3_AIRBNB_V2
GROUP BY CAT_VIBE_IA

-- QUEST√ÉO 5: Qual a localiza√ß√£o exata de cada im√≥vel para plotagem no mapa?
SELECT 
    SK_LISTING AS ID_IMOVEL, 
    NR_LATITUDE AS LATITUDE, 
    NR_LONGITUDE AS LONGITUDE, 
FROM TB__OK6YZB__GOLD_LISTINGS_PL_INGEST_S3_AIRBNB_V2
```

## Item 8 - Pipelines e Orquestra√ß√£o

Embora a execu√ß√£o dos scripts tenha sido realizada nas etapas anteriores, este item documenta a orquestra√ß√£o l√≥gica do fluxo de dados **(ELT/ETL)**. Devido a restri√ß√µes de acesso ao m√≥dulo de *Transforma√ß√£o/Intelligence* da plataforma Dadosfera, optei por arquitetar o pipeline utilizando a stack nativa do **Google Cloud Platform (Vertex AI + BigQuery)**, demonstrando adaptabilidade e conhecimentos de Nuvem.

### Arquitetura do Pipeline

O pipeline foi desenhado para ser idempotente e sequencial, garantindo que os dados fluam da origem bruta at√© a camada anal√≠tica com qualidade e enriquecimento.

```mermaid
graph LR
    A[üìÇ CSV Locais] -->|Upload| B(‚òÅÔ∏è Cloud Storage - Raw)
    B -->|Leitura| C{Vertex AI / Python}
    C -->|Valida√ß√£o| D[Great Expectations]
    C -->|Limpeza| E[Camada Silver]
    E -->|Enriquecimento| F[OpenAI API]
    F -->|Modelagem| G[BigQuery - Gold]
    G -->|Consumo| H[Dashboard]
```

### Detalhamento das Tasks

Abaixo, o fluxo de execu√ß√£o passo a passo (**Workflow**):

---

#### **Task 1: Ingest√£o (Data Ingestion)**

**A√ß√£o:**  
Upload dos arquivos brutos (`listings.csv`, `reviews.csv`) para o Bucket do **Google Cloud Storage** e **AWS S3**.

**Script:**  
- Upload via Console

**Objetivo:**  
Centralizar os dados na **Landing Zone (Raw)**, garantindo backup e disponibilidade para o ambiente de processamento.

---

#### **Task 2: Saneamento (Silver Layer)**

**A√ß√£o:**  
Leitura dos dados do Bucket e aplica√ß√£o de regras de limpeza via **Pandas**.

**Transforma√ß√µes:**
- Remo√ß√£o de colunas desnecess√°rias (PII ou irrelevantes para an√°lise) para otimizar storage  
- Tratamento de valores nulos e convers√£o de tipos (ex: `String ‚Üí Float` em colunas de pre√ßo)

**Data Quality:**  
Execu√ß√£o da suite de testes do **Great Expectations** (ver Item 7).

---

#### **Task 3: Enriquecimento com IA (Feature Engineering)**

**A√ß√£o:**  
Cria√ß√£o de colunas calculadas sem√¢nticas que n√£o existiam na base original.

**Processo:**
- Envio de micro-lotes de textos (Reviews / T√≠tulos) para a **API da OpenAI**

**Output:**  
Gera√ß√£o das colunas:
- `CAT_SENTIMENTO`
- `CAT_VIBE`
- `FLG_URGENCIA`

**Impacto:**  
Transforma√ß√£o de dados n√£o estruturados em dados tabulares prontos para consumo via SQL.

---

#### **Task 4: Modelagem e Carga (Gold Layer)**

**A√ß√£o:**  
Aplica√ß√£o das regras de neg√≥cio finais e persist√™ncia no **Data Warehouse**.

**Transforma√ß√µes:**
- Renomea√ß√£o de colunas para o padr√£o **CDM (Common Data Model)**
- Tradu√ß√£o de dom√≠nios (ex: `Entire home ‚Üí Casa Inteira`)

**Carga:**  
Escrita no **BigQuery** utilizando a biblioteca `pandas-gbq`.

---

### Decis√µes de Arquitetura

#### **1. Por que Pandas e n√£o Apache Spark?**

Uma decis√£o consciente de **FinOps (Engenharia de Custos)** foi tomada neste projeto.

**Volume de Dados:**  
O dataset do Airbnb Rio de Janeiro possui cerca de **300k a 500k registros** (*Small Data*).

**Justificativa:**  
O Pandas processa esse volume **em mem√≥ria (In-Memory)** em poucos segundos, utilizando uma m√°quina **e2-standard-4** de baixo custo.

**Trade-off:**  
A utiliza√ß√£o de um cluster Spark (Dataproc) traria:
- Overhead de tempo de start-up  
- Custo financeiro desnecess√°rio para essa volumetria  

O **Apache Spark** seria a escolha correta apenas se o volume escalasse para **Gigabytes ou Terabytes**.

---

#### **2. Adapta√ß√£o √† Plataforma**

Como n√£o foi poss√≠vel utilizar o pipeline visual da **Dadosfera** (limita√ß√£o de acesso), a mesma l√≥gica de transforma√ß√£o foi replicada utilizando o **Vertex AI Workbench**.

## Item 9 & Bonus - Data App & Solu√ß√µes de GenAI

Para consolidar toda a intelig√™ncia gerada nas camadas anteriores, foi desenvolvido um **Data App** interativo (constru√≠do em Streamlit). Esta aplica√ß√£o n√£o serve apenas para visualizar dados passados, mas atua como uma ferramenta prescritiva e generativa para dois perfis de usu√°rio: o **Anfitri√£o (Host)** e o **Investidor**.

O aplicativo foi dividido em tr√™s m√≥dulos estrat√©gicos:

### M√≥dulo 1: Market Intelligence (Dashboard)
*Foco: Visualiza√ß√£o e Diagn√≥stico de Mercado.*

Este m√≥dulo exibe os indicadores calculados na Camada Gold, permitindo uma vis√£o macro e micro do turismo no Rio de Janeiro.
* **Mapa de Calor:** Identifica√ß√£o de zonas de alta densidade de ofertas.
* **Filtros Din√¢micos:** Segmenta√ß√£o por Bairro, Faixa de Pre√ßo e "Vibe" (Classifica√ß√£o da IA).
* **An√°lise de Sentimento:** Gr√°ficos que mostram o que os h√≥spedes est√£o elogiando ou criticando em tempo real.

---

### M√≥dulo 2: O "Gerador de An√∫ncios Perfeitos" (GenAI)
*Foco: Ferramenta para Anfitri√µes (Hosts).*

Utilizando a API da OpenAI integrada ao Streamlit, criamos um assistente que resolve a "dor" de criar um an√∫ncio atrativo e precific√°-lo corretamente.

#### Como funciona:
1.  **Input do Usu√°rio:** O host seleciona as caracter√≠sticas do im√≥vel via *checkboxes* (ex: "Vista Mar", "Wi-Fi R√°pido", "Perto do Metr√¥") e define o bairro.
2.  **Motor de Precifica√ß√£o (Analytics):** O app consulta a base Gold, filtra im√≥veis similares no mesmo bairro e calcula a mediana de pre√ßo (`VLR_DIARIA_BRL`), sugerindo um valor competitivo.
3.  **Motor Criativo (LLM):** Um prompt engenheirado recebe as caracter√≠sticas e gera uma descri√ß√£o persuasiva (Copywriting) baseada nas melhores pr√°ticas de SEO do Airbnb.

> **Exemplo de Sa√≠da:**
> * *"Pre√ßo Sugerido: R$ 450,00/noite (5% abaixo da m√©dia da regi√£o para atrair os primeiros h√≥spedes)."*
> * *"Descri√ß√£o Gerada: Acorde com a brisa do mar neste apartamento exclusivo..."*

---

### M√≥dulo 3: O "Smart Investor" (Recomenda√ß√£o)
*Foco: Ferramenta para Investidores Imobili√°rios.*

Este m√≥dulo utiliza dados hist√≥ricos para encontrar oportunidades de investimento (Arbitragem), cruzando o or√ßamento do usu√°rio com a liquidez da regi√£o.

#### L√≥gica de Recomenda√ß√£o:
1.  **Input:** O usu√°rio informa quanto deseja pagar na parcela do financiamento (ex: R$ 3.000/m√™s).
2.  **C√°lculo de Viabilidade:** O sistema estima a receita potencial (Di√°ria M√©dia x Taxa de Ocupa√ß√£o Estimada via volume de Reviews).
3.  **An√°lise de "Blue Ocean":**
    * O algoritmo identifica bairros com **Alta Demanda** (Muitos reviews recentes).
    * Verifica a **Satura√ß√£o de Oferta** (Ex: O bairro tem muita procura por "Luxo", mas 90% dos an√∫ncios s√£o "Econ√¥micos"?).
4.  **Sugest√£o:** O app recomenda onde comprar e qual perfil de im√≥vel montar.

> **Cen√°rio de Exemplo:**
> *"Com uma parcela de R$ 3.000, sugerimos investir no bairro **Botafogo**. A regi√£o possui alta liquidez (ocupa√ß√£o constante). Notamos uma escassez de im√≥veis com perfil **'Home Office/Nomad'** (Internet r√°pida + Mesa), apesar da alta procura por este perfil na √°rea."*

---

### Stack Tecnol√≥gica do App
* **Frontend:** Streamlit (Python).
* **Backend de Dados:** Google BigQuery (Consultas SQL otimizadas).
* **Intelig√™ncia Artificial:** OpenAI API (`gpt-4o-mini`) para gera√ß√£o de texto e classifica√ß√£o.
* **Geospatial:** Plotly/Folium para renderiza√ß√£o de mapas interativos.