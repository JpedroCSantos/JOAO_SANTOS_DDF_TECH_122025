# üöÄ Case T√©cnico Dadosfera: Modern Data Platform & AI

![Status](https://img.shields.io/badge/Status-Em_Desenvolvimento-yellow)
![Python](https://img.shields.io/badge/Stack-Python_%7C_SQL-blue)
![Cloud](https://img.shields.io/badge/Cloud-AWS_%7C_Neon_%7C_Dadosfera-orange)

> **Autor:** Jo√£o Pedro Santos
> **Processo:** Engenharia de Dados - Dadosfera
> **Per√≠odo:** Dezembro/2025

---

## üéØ Objetivo do Projeto
Implementa√ß√£o ponta a ponta de uma Plataforma de Dados Moderna (Modern Data Stack) seguindo a arquitetura **Lakehouse**. O projeto simula um cen√°rio real de engenharia de dados, cobrindo desde a ingest√£o de m√∫ltiplas fontes at√© a aplica√ß√£o de Governan√ßa e Intelig√™ncia Artificial.

---
## üìÖ Item 0 - Planejamento e Ingest√£o

**Gest√£o √Ågil:** O acompanhamento das tarefas segue a metodologia Kanban.
üìä [**Acesse o Quadro do Projeto (Trello)**](https://trello.com/b/7aWCHtbz/dadosfera)

![Quadro Trello](/docs/images/trello_board.png)

### üí∞ Estimativa de Esfor√ßo e Custos (Story Points)

Para cumprir o requisito de **Estimativa de Custos e Aloca√ß√£o de Recursos** (Item 0 - Avan√ßado), este projeto adota o sistema de pontua√ß√£o baseado na sequ√™ncia de Fibonacci adaptada.

---

## üóÑÔ∏è Item 1 - Sele√ß√£o e Arquitetura de Dados

### O Pivot: De E-commerce para PropTech
Originalmente planejado para Varejo (Olist), o projeto realizou um **Pivot Estrat√©gico** para o setor de Turismo/Imobili√°rio.

* **Dataset:** [Inside Airbnb (Rio de Janeiro)](http://insideairbnb.com/get-the-data/)
* **Estrat√©gia de Volumetria:**
    * O dataset original de *Reviews* possui escala de Big Data (milh√µes de registros).
    * **Decis√£o de Arquitetura:** Para este case, foi aplicada uma filtragem estrat√©gica reduzindo a carga para **~300k linhas**.
    * **Objetivo:** Otimizar o tempo de processamento/custo da pipeline durante a fase de desenvolvimento, mantendo-se ainda **3x acima do requisito m√≠nimo** do case (>100k registros).

* **Justificativa T√©cnica:** A base oferece maior complexidade para engenharia de dados por incluir nativamente:
    1.  **Dados Geoespaciais (GIS):** Pol√≠gonos de bairros (GeoJSON).
    2.  **Dados Desestruturados:** Reviews de usu√°rios para an√°lise de NLP.
    3.  **Dados Relacionais:** Tabelas de propriedades e calend√°rio.

### Arquitetura "Hybrid-Cloud"
A solu√ß√£o integra servi√ßos best-of-breed para compor o Data Lake:
* **Landing Zone:** AWS S3 (Armazenamento de arquivos brutos).
* **Transactional Layer:** Neon PostgreSQL (Simula√ß√£o de banco de produ√ß√£o).
* **Platform Core:** Dadosfera (Ingest√£o, Cat√°logo e Processamento).

---
## ‚öôÔ∏è Pipelines de Ingest√£o (Item 2.1)
Implementa√ß√£o de pipelines segregadas por dom√≠nio de dados (**Data Mesh**), garantindo que cada tipo de arquivo tenha seu fluxo de tratamento espec√≠fico.

| Pipeline ID | Origem | Destino (Tabela) | Status | Descri√ß√£o |
| :--- | :--- | :--- | :--- | :--- |
| **PL_INGEST_S3_AIRBNB_LISTINGS** | AWS S3 | `PUBLIC.LISTINGS` | ‚úÖ | Dados cadastrais e financeiros (Core). |
| **PL_INGEST_S3_AIRBNB_REVIEWS** | AWS S3 | `PUBLIC.REVIEWS` | ‚úÖ | Logs de avalia√ß√µes (Alto Volume/Texto). |
| **PL_INGEST_S3_AIRBNB_GIS_ZONES** | AWS S3 | `PUBLIC.GIS_ZONES` | ‚úÖ | Dados vetoriais de mapas (GeoJSON). |
| **PL_INGEST_NEON_REFERENCE_DATA**| Neon DB | `PUBLIC.NEIGHBOURHOODS` | ‚úÖ | Replica√ß√£o de dados mestres do Postgres. |

---

## üìö Item 3 - Explora√ß√£o e Governan√ßa (Data Lake)

Nesta etapa, focou-se na organiza√ß√£o da **Landing Zone (Camada Bronze)** e na documenta√ß√£o dos ativos para garantir a democratiza√ß√£o do acesso.

### 1. Estrat√©gia de Cataloga√ß√£o
Os ativos foram classificados utilizando **Tags** na plataforma para identificar visualmente a camada e a fun√ß√£o de cada tabela:

* **`Bronze`**: Aplicada a todas as tabelas de ingest√£o (`listings`, `reviews`, `gis_zones`), indicando que cont√™m dados brutos (Raw) e imut√°veis da Landing Zone.
* **`Dimens√£o`**: Aplicada especificamente √† tabela `NEIGHBOURHOODS` (origem Neon), identificando-a antecipadamente como uma tabela de refer√™ncia (Master Data) para o modelo dimensional.

### 2. Dicion√°rio de Dados
A documenta√ß√£o detalhada de cada coluna, tipagem e regras de neg√≥cio foi externalizada para manter este README limpo.

üëâ **[Acesse o Dicion√°rio de Dados Completo (Docs)](docs/data_dictionary.md)**

### 3. Matriz de Riscos e Decis√µes T√©cnicas (ADR)
Registro de impedimentos encontrados durante a ingest√£o e as solu√ß√µes de contorno adotadas ("Workarounds").

| Decis√£o / Impedimento | Contexto T√©cnico | Solu√ß√£o Adotada (Trade-off) |
| :--- | :--- | :--- |
| **GeoJSON Aninhado (Nested Data)** | A ingest√£o do arquivo `neighbourhoods.geojson` resultou em uma √∫nica linha contendo um array JSON gigante, devido ao formato `FeatureCollection`. | **Decis√£o ELT:** Manter o dado aninhado na camada Bronze e realizar a explos√£o (`UNNEST`/`FLATTEN`) via SQL na etapa de transforma√ß√£o (Silver), preservando a fidelidade √† fonte. |
| **Uso de Owner no Neon** | O usu√°rio de servi√ßo `dadosfera_user` falhou ao ler metadados do sistema (`pg_catalog`) na conex√£o JDBC. | **Decis√£o:** Uso tempor√°rio do superusu√°rio `neondb_owner` para desbloquear o pipeline, documentado como D√≠vida T√©cnica de seguran√ßa. |


---

# Arquitetura de Processamento e Intelig√™ncia (Items 4, 5 & 6)

Para a execu√ß√£o das etapas de Qualidade de Dados, Enriquecimento com IA e Modelagem Dimensional, foi adotada uma arquitetura de **Computa√ß√£o Desacoplada (Decoupled Compute)**.

Esta decis√£o estrat√©gica visa garantir a reprodutibilidade do ambiente cient√≠fico e a agilidade no desenvolvimento, mantendo a compatibilidade total com a plataforma de destino (Dadosfera).

#### 1. Estrat√©gia de Processamento (Hybrid ELT)
Devido a restri√ß√µes de acesso ao m√≥dulo de computa√ß√£o nativo da plataforma SaaS durante a fase de avalia√ß√£o, implementou-se o padr√£o **"Bring Your Own Compute" (BYOC)**:

1.  **Extract (Cloud):** Os dados brutos residem na Landing Zone (AWS S3/Dadosfera).
2.  **Transform & Quality (Local/Container):** O processamento pesado (Valida√ß√£o GX, NLP com GPT-4, Modelagem Star Schema) √© executado em containers locais, simulando um *Worker Node* externo.
    * *Nota:* O c√≥digo foi desenvolvido utilizando bibliotecas padr√£o (Python SDKs), permitindo um *Lift-and-Shift* imediato para dentro da Dadosfera ou Databricks sem refatora√ß√£o.
3.  **Load (Cloud):** Os resultados processados (Camada Gold) s√£o re-ingestados no Data Lake da Dadosfera para consumo via Dashboard.

#### 2. Abstra√ß√£o de I/O (Data Mocking)
Para otimizar custos e lat√™ncia durante o ciclo de desenvolvimento, foi criada uma camada de abstra√ß√£o de leitura para os arquivos locais (`./data/raw/*.csv`) replicando a estrutura do S3.

## Item 4 - Data Quality & Saneamento (Great Expectations)

Para garantir a confiabilidade dos modelos de IA, implementou-se uma estrat√©gia rigorosa de **Quality Gates** utilizando a biblioteca **Great Expectations (GX)**. O processo foi dividido em duas etapas: Diagn√≥stico (Raw) e Valida√ß√£o Final (Silver).

### üïµÔ∏è‚Äç‚ôÇÔ∏è Fase 1: Diagn√≥stico da Camada Bronze (Raw)
A primeira execu√ß√£o do GX sobre os dados brutos revelou problemas cr√≠ticos que inviabilizariam o uso direto em Machine Learning:

* **Duplicidade:** 437 IDs de im√≥veis duplicados.
* **Integridade Num√©rica:** 3.789 registros com IDs "sujos" (erros de parser/cabe√ßalhos repetidos) nas tabelas de Reviews.
* **Regras de Neg√≥cio:** 4.398 im√≥veis com `price` nulo ou formatado incorretamente, o que quebraria c√°lculos financeiros.

> **Status Inicial:** ‚ùå FALHA (Expected)

---

## üõ†Ô∏è Item 4.1 (B√¥nus) - Transforma√ß√£o Silver & CDM

Para resolver os problemas detectados, foi desenvolvido o pipeline de transforma√ß√£o [`2_transform_silver.ipynb`](/nootbooks\02-transform_silver.ipynb). Al√©m da limpeza, foi implementado um **Common Data Model (CDM)**, padronizando a nomenclatura das colunas para um padr√£o corporativo leg√≠vel (Enterprise Naming Convention).

### 1. A√ß√µes de Saneamento
* **Cleaning:** Convers√£o for√ßada de tipagem (String -> Float/Int).
* **Filtering:** Remo√ß√£o autom√°tica de linhas onde `ID` ou `Price` eram nulos/inv√°lidos ("Garbage Collection").
* **Deduplication:** Aplica√ß√£o de `drop_duplicates` baseada na Chave Prim√°ria.

### 2. Common Data Model (Schema Padr√£o)
Ado√ß√£o de prefixos sem√¢nticos para facilitar o Self-Service BI:

| Prefixo | Significado | Exemplo Original | Exemplo CDM (Novo) |
| :--- | :--- | :--- | :--- |
| **SK_** | Surrogate/Source Key | `id` | `SK_LISTING` |
| **NM_** | Nome/Texto Curto | `neighbourhood` | `NM_BAIRRO` |
| **VLR_** | Valor Monet√°rio | `price` | `VLR_DIARIA_BRL` |
| **NR_** | N√∫mero/Coordenada | `latitude` | `NR_LATITUDE` |
| **QTD_** | Quantidade/M√©trica | `minimum_nights` | `QTD_MIN_NOITES` |

---

### üèÜ Fase 3: Valida√ß√£o Final (Quality Gate)

Ap√≥s a transforma√ß√£o, o Great Expectations foi re-executado sobre a camada **Silver**. O resultado comprova a efic√°cia do pipeline de engenharia:

**Relat√≥rio de Execu√ß√£o (Silver Layer):**
```text
üìä RELAT√ìRIO: Listings (Silver)
Status Global: ‚úÖ APROVADO
----------------------------------------
‚úÖ [SK_LISTING] Unicidade Garantida
‚úÖ [SK_LISTING] N√£o Nulo
‚úÖ [VLR_DIARIA_BRL] Formato Num√©rico Validado
‚úÖ [QTD_DIAS_DISPONIVEIS] Range L√≥gico (0-365) Validado

üìä RELAT√ìRIO: Reviews (Silver)
Status Global: ‚úÖ APROVADO
----------------------------------------
‚úÖ [SK_REVIEW] Formato Num√©rico Validado
‚úÖ [SK_LISTING] Integridade Referencial (FK)
‚úÖ [NM_REVIEWER] Preenchimento Obrigat√≥rio