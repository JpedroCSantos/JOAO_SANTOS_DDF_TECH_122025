# üöÄ Case T√©cnico Dadosfera: Modern Data Platform & AI

![Status](https://img.shields.io/badge/Status-Em_Desenvolvimento-yellow)
![Python](https://img.shields.io/badge/Stack-Python_%7C_SQL-blue)
![Cloud](https://img.shields.io/badge/Cloud-AWS_%7C_Neon_%7C_Dadosfera-orange)

> **Autor:** Jo√£o Pedro Santos
> **Processo:** Engenharia de Dados - Dadosfera
> **Per√≠odo:** Dezembro/2025

---

## Objetivo do Projeto
Implementa√ß√£o ponta a ponta de uma Plataforma de Dados Moderna (Modern Data Stack) seguindo a arquitetura **Lakehouse**. O projeto simula um cen√°rio real de engenharia de dados, cobrindo desde a ingest√£o de m√∫ltiplas fontes at√© a aplica√ß√£o de Governan√ßa e Intelig√™ncia Artificial.

---
## Item 0 - Planejamento e Ingest√£o

**Gest√£o √Ågil:** O acompanhamento das tarefas segue a metodologia Kanban.
üìä [**Acesse o Quadro do Projeto (Trello)**](https://trello.com/b/7aWCHtbz/dadosfera)

![Quadro Trello](/docs/images/trello_board.png)

### Estimativa de Esfor√ßo e Custos (Story Points)

Para cumprir o requisito de **Estimativa de Custos e Aloca√ß√£o de Recursos** (Item 0 - Avan√ßado), este projeto adota o sistema de pontua√ß√£o baseado na sequ√™ncia de Fibonacci adaptada.

---

## Item 1 - Sele√ß√£o e Arquitetura de Dados

### O Pivot: De E-commerce para PropTech
Originalmente planejado para Varejo (Olist), o projeto realizou um **Pivot Estrat√©gico** para o setor de Turismo/Imobili√°rio.

* **Dataset:** [Inside Airbnb (Rio de Janeiro)](http://insideairbnb.com/get-the-data/)
* **Estrat√©gia de Volumetria:**
    * O dataset original de *Reviews* possui escala de Big Data (milh√µes de registros).
    * **Decis√£o de Arquitetura:** Para este case, foi aplicada uma filtragem estrat√©gica reduzindo a carga para **~300k linhas**.
    * **Objetivo:** Otimizar o tempo de processamento/custo da pipeline durante a fase de desenvolvimento, mantendo-se ainda **3x acima do requisito m√≠nimo** do case (>100k registros).

* **Justificativa T√©cnica:** A base oferece maior complexidade para engenharia de dados por incluir nativamente:
    1.  **Dados Geoespaciais (GIS):** Pol√≠gonos de bairros (GeoJSON).
    2.  **Dados Desestruturados:** Reviews de usu√°rios para an√°lise de NLP.
    3.  **Dados Relacionais:** Tabelas de propriedades e calend√°rio.

### Arquitetura "Hybrid-Cloud"
A solu√ß√£o integra servi√ßos best-of-breed para compor o Data Lake:
* **Landing Zone:** AWS S3 (Armazenamento de arquivos brutos).
* **Transactional Layer:** Neon PostgreSQL (Simula√ß√£o de banco de produ√ß√£o).
* **Platform Core:** Dadosfera (Ingest√£o, Cat√°logo e Processamento).

---
## Pipelines de Ingest√£o (Item 2.1)
Implementa√ß√£o de pipelines segregadas por dom√≠nio de dados (**Data Mesh**), garantindo que cada tipo de arquivo tenha seu fluxo de tratamento espec√≠fico.

| Pipeline ID | Origem | Destino (Tabela) | Status | Descri√ß√£o |
| :--- | :--- | :--- | :--- | :--- |
| **PL_INGEST_S3_AIRBNB_LISTINGS** | AWS S3 | `PUBLIC.LISTINGS` | ‚úÖ | Dados cadastrais e financeiros (Core). |
| **PL_INGEST_S3_AIRBNB_REVIEWS** | AWS S3 | `PUBLIC.REVIEWS` | ‚úÖ | Logs de avalia√ß√µes (Alto Volume/Texto). |
| **PL_INGEST_S3_AIRBNB_GIS_ZONES** | AWS S3 | `PUBLIC.GIS_ZONES` | ‚úÖ | Dados vetoriais de mapas (GeoJSON). |
| **PL_INGEST_NEON_REFERENCE_DATA**| Neon DB | `PUBLIC.NEIGHBOURHOODS` | ‚úÖ | Replica√ß√£o de dados mestres do Postgres. |

---

## Item 3 - Explora√ß√£o e Governan√ßa (Data Lake)

Nesta etapa, focou-se na organiza√ß√£o da **Landing Zone (Camada Bronze)** e na documenta√ß√£o dos ativos para garantir a democratiza√ß√£o do acesso.

### 1. Estrat√©gia de Cataloga√ß√£o
Os ativos foram classificados utilizando **Tags** na plataforma para identificar visualmente a camada e a fun√ß√£o de cada tabela:

* **`Bronze`**: Aplicada a todas as tabelas de ingest√£o (`listings`, `reviews`, `gis_zones`), indicando que cont√™m dados brutos (Raw) e imut√°veis da Landing Zone.
* **`Dimens√£o`**: Aplicada especificamente √† tabela `NEIGHBOURHOODS` (origem Neon), identificando-a antecipadamente como uma tabela de refer√™ncia (Master Data) para o modelo dimensional.

### 2. Dicion√°rio de Dados
A documenta√ß√£o detalhada de cada coluna, tipagem e regras de neg√≥cio foi externalizada para manter este README limpo.

üëâ **[Acesse o Dicion√°rio de Dados Completo (Docs)](docs/data_dictionary.md)**

### 3. Matriz de Riscos e Decis√µes T√©cnicas (ADR)
Registro de impedimentos encontrados durante a ingest√£o e as solu√ß√µes de contorno adotadas ("Workarounds").

| Decis√£o / Impedimento | Contexto T√©cnico | Solu√ß√£o Adotada (Trade-off) |
| :--- | :--- | :--- |
| **GeoJSON Aninhado (Nested Data)** | A ingest√£o do arquivo `neighbourhoods.geojson` resultou em uma √∫nica linha contendo um array JSON gigante, devido ao formato `FeatureCollection`. | **Decis√£o ELT:** Manter o dado aninhado na camada Bronze e realizar a explos√£o (`UNNEST`/`FLATTEN`) via SQL na etapa de transforma√ß√£o (Silver), preservando a fidelidade √† fonte. |
| **Uso de Owner no Neon** | O usu√°rio de servi√ßo `dadosfera_user` falhou ao ler metadados do sistema (`pg_catalog`) na conex√£o JDBC. | **Decis√£o:** Uso tempor√°rio do superusu√°rio `neondb_owner` para desbloquear o pipeline, documentado como D√≠vida T√©cnica de seguran√ßa. |


---

## Arquitetura de Processamento e Intelig√™ncia (Items 4, 5 & 6)

Para a execu√ß√£o das etapas de Qualidade de Dados, Enriquecimento com IA e Modelagem Dimensional, foi adotada uma arquitetura de **Computa√ß√£o Desacoplada (Decoupled Compute)**.

Esta decis√£o estrat√©gica visa garantir a reprodutibilidade do ambiente cient√≠fico e a agilidade no desenvolvimento, mantendo a compatibilidade total com a plataforma de destino (Dadosfera).

#### 1. Estrat√©gia de Processamento (Hybrid ELT)
Devido a restri√ß√µes de acesso ao m√≥dulo de computa√ß√£o nativo da plataforma SaaS durante a fase de avalia√ß√£o, implementou-se o padr√£o **"Bring Your Own Compute" (BYOC)**:

1.  **Extract (Cloud):** Os dados brutos residem na Landing Zone (AWS S3/Dadosfera).
2.  **Transform & Quality (Local/Container):** O processamento pesado (Valida√ß√£o GX, NLP com GPT-4, Modelagem Star Schema) √© executado em containers locais, simulando um *Worker Node* externo.
    * *Nota:* O c√≥digo foi desenvolvido utilizando bibliotecas padr√£o (Python SDKs), permitindo um *Lift-and-Shift* imediato para dentro da Dadosfera ou Databricks sem refatora√ß√£o.
3.  **Load (Cloud):** Os resultados processados (Camada Gold) s√£o re-ingestados no Data Lake da Dadosfera para consumo via Dashboard.

#### 2. Abstra√ß√£o de I/O (Data Mocking)
Para otimizar custos e lat√™ncia durante o ciclo de desenvolvimento, foi criada uma camada de abstra√ß√£o de leitura para os arquivos locais (`./data/raw/*.csv`) replicando a estrutura do S3.

## Item 4 - Data Quality & Saneamento (Great Expectations)

Para garantir a confiabilidade dos modelos de IA, implementou-se uma estrat√©gia rigorosa de **Quality Gates** utilizando a biblioteca **Great Expectations (GX)**. O processo foi dividido em duas etapas: Diagn√≥stico (Raw) e Valida√ß√£o Final (Silver).

### Fase 1: Diagn√≥stico da Camada Bronze (Raw)
A primeira execu√ß√£o do GX sobre os dados brutos revelou problemas cr√≠ticos que inviabilizariam o uso direto em Machine Learning:

* **Duplicidade:** 437 IDs de im√≥veis duplicados.
* **Integridade Num√©rica:** 3.789 registros com IDs "sujos" (erros de parser/cabe√ßalhos repetidos) nas tabelas de Reviews.
* **Regras de Neg√≥cio:** 4.398 im√≥veis com `price` nulo ou formatado incorretamente, o que quebraria c√°lculos financeiros.

> **Status Inicial:** ‚ùå FALHA (Expected)

---

## Item 4.1 (B√¥nus) - Transforma√ß√£o Silver & CDM

Para resolver os problemas detectados, foi desenvolvido o pipeline de transforma√ß√£o [`2_transform_silver.ipynb`](/nootbooks\02-transform_silver.ipynb). Al√©m da limpeza, foi implementado um **Common Data Model (CDM)**, padronizando a nomenclatura das colunas para um padr√£o corporativo leg√≠vel (Enterprise Naming Convention).

### 1. A√ß√µes de Saneamento
* **Cleaning:** Convers√£o for√ßada de tipagem (String -> Float/Int).
* **Filtering:** Remo√ß√£o autom√°tica de linhas onde `ID` ou `Price` eram nulos/inv√°lidos ("Garbage Collection").
* **Deduplication:** Aplica√ß√£o de `drop_duplicates` baseada na Chave Prim√°ria.

### 2. Common Data Model (Schema Padr√£o)
Ado√ß√£o de prefixos sem√¢nticos para facilitar o Self-Service BI:

| Prefixo | Significado | Exemplo Original | Exemplo CDM (Novo) |
| :--- | :--- | :--- | :--- |
| **SK_** | Surrogate/Source Key | `id` | `SK_LISTING` |
| **NM_** | Nome/Texto Curto | `neighbourhood` | `NM_BAIRRO` |
| **VLR_** | Valor Monet√°rio | `price` | `VLR_DIARIA_BRL` |
| **NR_** | N√∫mero/Coordenada | `latitude` | `NR_LATITUDE` |
| **QTD_** | Quantidade/M√©trica | `minimum_nights` | `QTD_MIN_NOITES` |

---

### Fase 3: Valida√ß√£o Final (Quality Gate)

Ap√≥s a transforma√ß√£o, o Great Expectations foi re-executado sobre a camada **Bronze**. O resultado comprova a efic√°cia do pipeline de engenharia:

**Relat√≥rio de Execu√ß√£o (Silver Layer):**
```text
üìä RELAT√ìRIO: Listings (Silver)
Status Global: ‚úÖ APROVADO
----------------------------------------
‚úÖ [SK_LISTING] Unicidade Garantida
‚úÖ [SK_LISTING] N√£o Nulo
‚úÖ [VLR_DIARIA_BRL] Formato Num√©rico Validado
‚úÖ [QTD_DIAS_DISPONIVEIS] Range L√≥gico (0-365) Validado

üìä RELAT√ìRIO: Reviews (Silver)
Status Global: ‚úÖ APROVADO
----------------------------------------
‚úÖ [SK_REVIEW] Formato Num√©rico Validado
‚úÖ [SK_LISTING] Integridade Referencial (FK)
‚úÖ [NM_REVIEWER] Preenchimento Obrigat√≥rio
```

## Item 5 - Enriquecimento com GenAI & LLMs (Feature Engineering)

Para extrair valor dos dados desestruturados (textos livres em Reviews e T√≠tulos de An√∫ncios), foi implementado um pipeline de **Processamento de Linguagem Natural (NLP)** utilizando a API da OpenAI.

O objetivo n√£o foi apenas "usar IA", mas sim transformar texto em colunas estruturadas para o Dashboard (Item 9), permitindo responder perguntas como: *"Qual o sentimento m√©dio dos h√≥spedes?"* ou *"Im√≥veis com vista para o mar s√£o mais caros?"*.

### Estrat√©gia e FinOps (Amostragem Inteligente)
Devido ao volume de dados (300k+ registros), processar a base inteira seria ineficiente e custoso para uma Prova de Conceito (PoC). Adotou-se uma estrat√©gia de **Smart Sampling** com foco em representatividade e economia:

1.  **Amostragem de Reviews (1.000 registros):**
    * **Top 500:** Reviews mais recentes/relevantes (Head).
    * **Random 500:** Sele√ß√£o aleat√≥ria do restante da cauda (Tail) para evitar vi√©s temporal.
2.  **Integridade Referencial de Listings:**
    * Sele√ß√£o autom√°tica dos im√≥veis (`SK_LISTING`) citados nos reviews acima.
    * *Backfill* aleat√≥rio at√© completar 1.000 im√≥veis, garantindo massa de dados para an√°lise cruzada.
3.  **Escolha do Modelo:**
    * **Modelo:** `gpt-4o-mini`.
    * **Custo Estimado da Opera√ß√£o:** < $0.10 USD (para processar os 2.000 registros).

### Engenharia de Prompt (As Miss√µes da IA)

O pipeline executa duas "miss√µes" distintas de classifica√ß√£o, for√ßando a sa√≠da em formato JSON (`response_format={"type": "json_object"}`) para garantir a integra√ß√£o direta com o Pandas.

#### Miss√£o A: An√°lise de Sentimento (Tabela `fact_reviews`)
Transforma coment√°rios subjetivos em m√©tricas quantitativas.
* **Prompt:** *"Atue como um especialista em Customer Experience. Analise o review e retorne um JSON."*
* **Features Geradas:**
    * `SENTIMENTO`: Positivo, Neutro, Negativo.
    * `TOPICO_PRINCIPAL`: Limpeza, Localiza√ß√£o, Ru√≠do, Atendimento, etc.
    * `SUB_TOPICO`: Conforto, Comunica√ß√£o, Valor, Comodidades, Outro.
    * `TOM_DE_URGENCIA`: Avalia√ß√£o precisa de uma a√ß√£o urgente.

#### Miss√£o B: Categoriza√ß√£o de Im√≥veis (Tabela `dim_listings`)
Extrai atributos de neg√≥cio a partir do t√≠tulo criativo do an√∫ncio.
* **Prompt:** *"Atue como um Corretor de Im√≥veis S√™nior. Analise o t√≠tulo do an√∫ncio e classifique."*
* **Features Geradas:**
    * `CATEGORIA_VIBE`: Luxo, Econ√¥mico, Rom√¢ntico, Familiar, Moderno.
    * `TIPO_VISTA`: Vista Mar, Urbana, Natureza, Sem Vista.
    * `PRINCIPAL_CARACTERISTICA`: Palavra √∫nica palavra que destaca o im√≥vel.
    * `PONTO_FORTE`: Resumo de 3 palavras (ex: "Perto do Metr√¥").

### Exemplo de Resultados (De/Para)

| Input (Texto Original) | Output (Enriquecido via LLM) |
| :--- | :--- |
| **Review:** *"O apartamento √© lindo, mas o barulho da rua n√£o deixou a gente dormir. A limpeza estava ok."* | `{ "sentimento": "Negativo", "topico": "Ru√≠do", "sub_topico":Conforto, "tom_de_urgencia": false }` |
| **Listing:** *"COBERTURA DUPLEX VISTA MAR - COPACABANA POSTO 6"* | `{ "vibe": "Luxo", "vista": "Mar", "principal_caracteristica": "Localidade", "destaque": "Cobertura Duplex" }` |

### Persist√™ncia
Os dados enriquecidos foram salvos separadamente na camada Gold para consumo do Data App:
* `data/gold/sample_reviews_enriched.csv`
* `data/gold/sample_listings_enriched.csv`

## Item 6 - Modelagem de Dados (Data Warehouse)

Para a constru√ß√£o da camada **Gold** no Google BigQuery, adotou-se a metodologia **Dimensional (Kimball)**, criando um modelo **Star Schema** (Esquema Estrela).

Essa modelagem foi escolhida por ser otimizada para leitura em ferramentas de BI (Power BI/Streamlit) e facilitar consultas anal√≠ticas (OLAP), ao contr√°rio do modelo normalizado (3NF) que prioriza a escrita (OLTP).

### Estrutura do Schema

O modelo √© centrado no evento de avalia√ß√£o ("Review"), cercado pelas dimens√µes de contexto:

#### 1. Fato: `FACT_REVIEWS`
Tabela transacional contendo m√©tricas e chaves estrangeiras.
* **Granularidade:** 1 linha por avalia√ß√£o √∫nica.
* **M√©tricas:** `TOM_DE_URGENCIA` (Boolean/Flag indicando cr√≠ticas severas que exigem a√ß√£o imediata).
* **Dimens√£o Degenerada:** `SENTIMENTO` (Positivo/Neutro/Negativo).

#### 2. Dimens√£o: `DIM_LISTINGS`
Cont√©m os atributos descritivos do im√≥vel, enriquecidos com Features de IA.
* **Atributos:** `NM_ANUNCIO`, `VLR_DIARIA`, `CAT_VIBE_IA` (Luxo/Econ√¥mico...), `CAT_VISTA_IA` (Mar/Urbana...).
* **Slowly Changing Dimension (SCD):** Tratada como Tipo 1 (Sobrescreve valor atual) para simplifica√ß√£o do case.

#### 3. Dimens√£o: `DIM_NEIGHBOURHOODS` (GeoSpatial)
Tabela espacial oriunda do processamento do arquivo `neighbourhoods.geojson`.
* **Feature Especial:** Coluna do tipo `GEOGRAPHY` (Pol√≠gono) no BigQuery, permitindo queries espaciais (ex: `ST_CONTAINS`) para filtrar reviews dentro de zonas geogr√°ficas espec√≠ficas no mapa.

#### 4. Dimens√£o: `DIM_TEMPO`
Calend√°rio fiscal/civil para an√°lises de sazonalidade.
* **Atributos:** Ano, M√™s, Dia da Semana, Flag de Feriado, Flag de Alta Temporada.

---

### Diagrama de Entidade-Relacionamento (DER)

A figura abaixo representa a arquitetura f√≠sica implementada:

![Diagrama de Mermaid](/docs/images/mermaid_diagram.png)